/*======================================================================*/
/* Europa firmware verification linker script                           */
/*                                                                      */
/*                                                                      */
/* This file was autogenerated using ld_generator.py and verifsdk.yaml  */
/* File generated at 2025-01-10, 09:06:51.                              */
/*======================================================================*/

#include "memorymap.h"
#include "stack.h"

/*----------------------------------------------------------------------*/
/* Setup                                                                */
/*----------------------------------------------------------------------*/

OUTPUT_ARCH( "riscv" )

/* Entry point: used by Spike */
#ifdef SYSTEM_AICORE
ENTRY(aicore0__start)
#else
ENTRY(_start)
#endif

/* Entry point: used by Spike */
#ifdef SYSTEM_AICORE
ENTRY(aicore1__start)
#else
ENTRY(_start)
#endif

/* Entry point: used by Spike */
#ifdef SYSTEM_AICORE
ENTRY(aicore2__start)
#else
ENTRY(_start)
#endif

/* Entry point: used by Spike */
#ifdef SYSTEM_AICORE
ENTRY(aicore3__start)
#else
ENTRY(_start)
#endif

/* Entry point: used by Spike */
#ifdef SYSTEM_AICORE
ENTRY(aicore4__start)
#else
ENTRY(_start)
#endif

/* Entry point: used by Spike */
#ifdef SYSTEM_AICORE
ENTRY(aicore5__start)
#else
ENTRY(_start)
#endif

/* Entry point: used by Spike */
#ifdef SYSTEM_AICORE
ENTRY(aicore6__start)
#else
ENTRY(_start)
#endif

/* Entry point: used by Spike */
#ifdef SYSTEM_AICORE
ENTRY(aicore7__start)
#else
ENTRY(_start)
#endif

/*----------------------------------------------------------------------*/
/* UVM SW IPC memory allocation */
/*----------------------------------------------------------------------*/

/* Sizes: 64 bytes per HART, rounded up to next power of two */
#define UVM_SW_IPC_SIZE        (0x40)
#define APU_UVM_SW_IPC_SIZE    (UVM_SW_IPC_SIZE * 6)     /* 6 HARTs */
#define AICORE_UVM_SW_IPC_SIZE (UVM_SW_IPC_SIZE * 8)     /* 1 HART per instance */
#define PVE_UVM_SW_IPC_SIZE    (UVM_SW_IPC_SIZE * 8 * 2) /* 8 HARTs per instance */

/* Addresses: placed at the end of the sys_spm.
 * These are hard-coded in UVM code.
 * Memory Map:
 *
 * SYS_SPM_BASE                            SYS_SPM_BASE + SYS_SPM_SIZE
 *      +-----------------------------------------------+
 *      |        | pve_1 | pve_0 | aicore 7-0 | apu 5-0 |
 *      +-----------------------------------------------+
 */
#define UVM_SW_IPC_BASE        (SYS_SPM_BASE + SYS_SPM_SIZE - UVM_SW_IPC_SIZE)

/*----------------------------------------------------------------------*/
/* Sections                                                             */
/*----------------------------------------------------------------------*/

/*
 * WARNING(europa!248):
 *
 * Consider the following snippet:
 *     .text ALIGN(16) : { *(.text) }
 *
 * When using the GNU linker (ld.bfd), the section's start address will be
 * 16-byte aligned. This is expected behavior.
 *
 * When using the LLVM linker (ld.lld) however, this will not work. As a
 * workaround, use the following snippet:
 *     . = ALIGN(16);
 *     .text : { *(.text) }
 */


MEMORY
{
  /* top */
  sys_spm     : ORIGIN = SYS_SPM_BASE, LENGTH = SYS_SPM_SIZE - APU_UVM_SW_IPC_SIZE - AICORE_UVM_SW_IPC_SIZE - PVE_UVM_SW_IPC_SIZE
  dram        : ORIGIN = DDR_1_BASE,   LENGTH = DDR_1_SIZE
  l2          : ORIGIN = L2_BASE,   LENGTH = L2_SIZE

  /* AI cores */
  aicore0_l1  : ORIGIN = AICORE_0_L1_BASE,  LENGTH = AICORE_0_L1_SIZE
  aicore0_spm : ORIGIN = AICORE_0_SPM_BASE, LENGTH = AICORE_0_SPM_SIZE
  aicore1_l1  : ORIGIN = AICORE_1_L1_BASE,  LENGTH = AICORE_1_L1_SIZE
  aicore1_spm : ORIGIN = AICORE_1_SPM_BASE, LENGTH = AICORE_1_SPM_SIZE
  aicore2_l1  : ORIGIN = AICORE_2_L1_BASE,  LENGTH = AICORE_2_L1_SIZE
  aicore2_spm : ORIGIN = AICORE_2_SPM_BASE, LENGTH = AICORE_2_SPM_SIZE
  aicore3_l1  : ORIGIN = AICORE_3_L1_BASE,  LENGTH = AICORE_3_L1_SIZE
  aicore3_spm : ORIGIN = AICORE_3_SPM_BASE, LENGTH = AICORE_3_SPM_SIZE
  aicore4_l1  : ORIGIN = AICORE_4_L1_BASE,  LENGTH = AICORE_4_L1_SIZE
  aicore4_spm : ORIGIN = AICORE_4_SPM_BASE, LENGTH = AICORE_4_SPM_SIZE
  aicore5_l1  : ORIGIN = AICORE_5_L1_BASE,  LENGTH = AICORE_5_L1_SIZE
  aicore5_spm : ORIGIN = AICORE_5_SPM_BASE, LENGTH = AICORE_5_SPM_SIZE
  aicore6_l1  : ORIGIN = AICORE_6_L1_BASE,  LENGTH = AICORE_6_L1_SIZE
  aicore6_spm : ORIGIN = AICORE_6_SPM_BASE, LENGTH = AICORE_6_SPM_SIZE
  aicore7_l1  : ORIGIN = AICORE_7_L1_BASE,  LENGTH = AICORE_7_L1_SIZE
  aicore7_spm : ORIGIN = AICORE_7_SPM_BASE, LENGTH = AICORE_7_SPM_SIZE

  /* PVEs */
  pve0_spm    : ORIGIN = PVE_0_SPM_BASE,  LENGTH = PVE_0_SPM_SIZE
  pve0_l1_0   : ORIGIN = PVE_0_L1_0_BASE, LENGTH = PVE_0_L1_0_SIZE
  pve0_l1_1   : ORIGIN = PVE_0_L1_1_BASE, LENGTH = PVE_0_L1_1_SIZE
  pve0_l1_2   : ORIGIN = PVE_0_L1_2_BASE, LENGTH = PVE_0_L1_2_SIZE
  pve0_l1_3   : ORIGIN = PVE_0_L1_3_BASE, LENGTH = PVE_0_L1_3_SIZE
  pve1_spm    : ORIGIN = PVE_1_SPM_BASE,  LENGTH = PVE_1_SPM_SIZE
  pve1_l1_0   : ORIGIN = PVE_1_L1_0_BASE, LENGTH = PVE_1_L1_0_SIZE
  pve1_l1_1   : ORIGIN = PVE_1_L1_1_BASE, LENGTH = PVE_1_L1_1_SIZE
  pve1_l1_2   : ORIGIN = PVE_1_L1_2_BASE, LENGTH = PVE_1_L1_2_SIZE
  pve1_l1_3   : ORIGIN = PVE_1_L1_3_BASE, LENGTH = PVE_1_L1_3_SIZE
}

SECTIONS
{
  /* === */
  /* APU */
  /* === */
#if PROCESSOR_APU
  /* APU boot code */
  .text.init : ALIGN(64) {
    *(.text.init)
  } > sys_spm
  ASSERT(
    ADDR(.text.init) == ORIGIN(sys_spm),
    "Error: APU boot code not at start of Sys-SPM"
  )

  /* magic memory for FESVR communication */
  .tohost : ALIGN(0x1000) {
    *(.tohost)
    *(.*.tohost)
    . = ALIGN(0x1000); /* ensure proper alignment of next section */
  } > sys_spm

  /* APU code */
  .text : ALIGN(64) {
    *(.text .text.*)
  } > sys_spm

  /* APU data/BSS*/
  .rodata : ALIGN(64) {
    *(.rodata  .rodata.*)
  } > sys_spm
  .data : ALIGN(64) {
    *(.data .data.*)
  } > sys_spm
  .sdata : ALIGN(64) {
    __global_pointer$ = . + 0x800;
    *(.srodata .srodata.*)
    *(.sdata .sdata.*)
    *(.gnu.linkonce.s.*)
  } > sys_spm
  /* BSS: will be zero-initialized by runtime to ensure it is zero even when
   *      side-loading binary using GDB */
  .sbss : ALIGN(64) {
    _bss_begin = .;
    *(.sbss .sbss.*)
    *(.scommon .scommon.*)
    *(.gnu.linkonce.sb.*)
  } > sys_spm
  .bss : ALIGN(64) {
    *(.bss)
    . = ALIGN(64); /* ensure _bss_end is 64-byte aligned */
    _bss_end = .;
  } > sys_spm
#endif

#if SYSTEM_TOP
  /* For the top system, put all .tdata sections consecutively into Sys-SPM. */
  /* thread-local data/BSS for all processors */
  /* 64-byte aligned as this is the same alignment that will be used at runtime */
  . = ALIGN(64);
  _thread_pointer = .; /* required to calculate thread-pointer offset on all processors */

  /* .tdata and .tbss are merged to ensure they are both allocated properly.
   * LLD has some weird behavior where it overlaps them when they are put into
   * separate output sections. */

  /* TLS for APU */
  .tdata : ALIGN(64) {
    _tdata_begin = .;
    *(.tdata .tdata.*)
    . = ALIGN(64); /* required to ensure proper alignment at runtime as .tbss will be placed immediately after .tdata at runtime */
    _tdata_end = .;
    _tbss_begin = .;
    *(.tbss .tbss.*)
    . = ALIGN(64);
    _tbss_end = .;
    _tls_alloc_size = _tbss_end - _tdata_begin;

  /* AICORE .tdata/.tbss placed here contiguously */
#if PROCESSOR_AICORE0
    /* TLS for AICORE 0 */
    aicore0__tdata_begin = .;
    *(.aicore0.tdata .aicore0.tdata.*)
    . = ALIGN(64);
    aicore0__tdata_end = .;
    aicore0__tbss_begin = .;
    *(.aicore0.tbss .aicore0.tbss.*)
    . = ALIGN(64);
    aicore0__tbss_end = .;
    aicore0__tls_alloc_size = aicore0__tbss_end - aicore0__tdata_begin;
#endif

#if PROCESSOR_AICORE1
    /* TLS for AICORE 1 */
    aicore1__tdata_begin = .;
    *(.aicore1.tdata .aicore1.tdata.*)
    . = ALIGN(64);
    aicore1__tdata_end = .;
    aicore1__tbss_begin = .;
    *(.aicore1.tbss .aicore1.tbss.*)
    . = ALIGN(64);
    aicore1__tbss_end = .;
    aicore1__tls_alloc_size = aicore1__tbss_end - aicore1__tdata_begin;
#endif

#if PROCESSOR_AICORE2
    /* TLS for AICORE 2 */
    aicore2__tdata_begin = .;
    *(.aicore2.tdata .aicore2.tdata.*)
    . = ALIGN(64);
    aicore2__tdata_end = .;
    aicore2__tbss_begin = .;
    *(.aicore2.tbss .aicore2.tbss.*)
    . = ALIGN(64);
    aicore2__tbss_end = .;
    aicore2__tls_alloc_size = aicore2__tbss_end - aicore2__tdata_begin;
#endif

#if PROCESSOR_AICORE3
    /* TLS for AICORE 3 */
    aicore3__tdata_begin = .;
    *(.aicore3.tdata .aicore3.tdata.*)
    . = ALIGN(64);
    aicore3__tdata_end = .;
    aicore3__tbss_begin = .;
    *(.aicore3.tbss .aicore3.tbss.*)
    . = ALIGN(64);
    aicore3__tbss_end = .;
    aicore3__tls_alloc_size = aicore3__tbss_end - aicore3__tdata_begin;
#endif

#if PROCESSOR_AICORE4
    /* TLS for AICORE 4 */
    aicore4__tdata_begin = .;
    *(.aicore4.tdata .aicore4.tdata.*)
    . = ALIGN(64);
    aicore4__tdata_end = .;
    aicore4__tbss_begin = .;
    *(.aicore4.tbss .aicore4.tbss.*)
    . = ALIGN(64);
    aicore4__tbss_end = .;
    aicore4__tls_alloc_size = aicore4__tbss_end - aicore4__tdata_begin;
#endif

#if PROCESSOR_AICORE5
    /* TLS for AICORE 5 */
    aicore5__tdata_begin = .;
    *(.aicore5.tdata .aicore5.tdata.*)
    . = ALIGN(64);
    aicore5__tdata_end = .;
    aicore5__tbss_begin = .;
    *(.aicore5.tbss .aicore5.tbss.*)
    . = ALIGN(64);
    aicore5__tbss_end = .;
    aicore5__tls_alloc_size = aicore5__tbss_end - aicore5__tdata_begin;
#endif

#if PROCESSOR_AICORE6
    /* TLS for AICORE 6 */
    aicore6__tdata_begin = .;
    *(.aicore6.tdata .aicore6.tdata.*)
    . = ALIGN(64);
    aicore6__tdata_end = .;
    aicore6__tbss_begin = .;
    *(.aicore6.tbss .aicore6.tbss.*)
    . = ALIGN(64);
    aicore6__tbss_end = .;
    aicore6__tls_alloc_size = aicore6__tbss_end - aicore6__tdata_begin;
#endif

#if PROCESSOR_AICORE7
    /* TLS for AICORE 7 */
    aicore7__tdata_begin = .;
    *(.aicore7.tdata .aicore7.tdata.*)
    . = ALIGN(64);
    aicore7__tdata_end = .;
    aicore7__tbss_begin = .;
    *(.aicore7.tbss .aicore7.tbss.*)
    . = ALIGN(64);
    aicore7__tbss_end = .;
    aicore7__tls_alloc_size = aicore7__tbss_end - aicore7__tdata_begin;
#endif

  /* PVE .tdata/.tbss placed here contiguously */
#if PROCESSOR_PVE0
    /* TLS for PVE 0 */
    pve0__tdata_begin = .;
    *(.pve0.tdata .pve0.tdata.*)
    . = ALIGN(64);
    pve0__tdata_end = .;
    pve0__tbss_begin = .;
    *(.pve0.tbss .pve0.tbss.*)
    . = ALIGN(64);
    pve0__tbss_end = .;
    pve0__tls_alloc_size = pve0__tbss_end - pve0__tdata_begin;
#endif

#if PROCESSOR_PVE1
    /* TLS for PVE 1 */
    pve1__tdata_begin = .;
    *(.pve1.tdata .pve1.tdata.*)
    . = ALIGN(64);
    pve1__tdata_end = .;
    pve1__tbss_begin = .;
    *(.pve1.tbss .pve1.tbss.*)
    . = ALIGN(64);
    pve1__tbss_end = .;
    pve1__tls_alloc_size = pve1__tbss_end - pve1__tdata_begin;
#endif

  } > sys_spm
#endif

#if PROCESSOR_APU
  .runtime.tls : ALIGN(64) {
    _tls_begin = .;
    . = . + 6 * _tls_alloc_size;
    _tls_end = .;
  } > sys_spm
  .runtime.stack : ALIGN(64) {
    _stack_begin = .;
    . = . + 6 * APU_STACK_SIZE;
    _stack_end = .;
  } > sys_spm

  .ddr : ALIGN(64) {
    *(.ddr .ddr.*)
  } > dram

  /* magic memory for UVM SW IPC communication */
  PROVIDE(_uvm_sw_ipc_mem = UVM_SW_IPC_BASE);
#endif

/* Always enable explicit allocation to system SPM from any core */
.sys_spm : ALIGN(64) {
  *(*.sys_spm *.sys_spm.*)
} > sys_spm

/* Always enable explicit allocation to L2 memory from any core */
.l2 : ALIGN(64) {
  *(*.l2 *.l2.*)
} > l2

  /* ======= */
  /* AICORE0 */
  /* ======= */
#if PROCESSOR_AICORE0
  .aicore0.text : ALIGN(64) {
    KEEP(*(.aicore0.text.init))
    *(.aicore0.text .aicore0.text.*)
  } > aicore0_spm
  ASSERT(
    ADDR(.aicore0.text) == ORIGIN(aicore0_spm),
    "Error: AICORE0 boot code not at start of AICORE0 SPM"
  )
  .aicore0.data : ALIGN(64) {
    *(.aicore0.operation_data_type.*)
    *(.aicore0.rodata .aicore0.rodata.*)
    *(.aicore0.data .aicore0.data.*)
  } > aicore0_spm
  .aicore0.sdata : ALIGN(64) {
    aicore0___global_pointer$ = . + 0x800;
    *(.aicore0.srodata .aicore0.srodata.*)
    *(.aicore0.sdata .aicore0.sdata.*)
  } > aicore0_spm
  .aicore0.sbss : ALIGN(64) {
    aicore0__bss_begin = .;
    *(.aicore0.sbss .aicore0.sbss.*)
  } > aicore0_spm
  .aicore0.bss : ALIGN(64) {
    *(.aicore0.bss .aicore0.bss.*)
    aicore0__bss_end = .;
  } > aicore0_spm

  /* Enable explicit allocation to AI Core 0 internal SPM from any core */
  .aicore0.spm : ALIGN(64) {
    *(*.aicore0.spm *.aicore0.spm.*)
  } > aicore0_spm

#ifndef SYSTEM_TOP
  /* TLS for AICORE 0 (standalone) */
  .aicore0.tdata : ALIGN(64) {
    aicore0__tdata_begin = .;
    *(.aicore0.tdata .aicore0.tdata.*)
    . = ALIGN(64);
    aicore0__tdata_end = .;
    aicore0__tbss_begin = .;
    *(.aicore0.tbss .aicore0.tbss.*)
    . = ALIGN(64);
    aicore0__tbss_end = .;
  } > aicore0_spm
  aicore0__tls_alloc_size = aicore0__tbss_end - aicore0__tdata_begin;

  /* magic memory for FESVR communication */
  .tohost : ALIGN(0x1000) {
    *(.tohost)
    *(.*.tohost)
    . = ALIGN(0x1000); /* ensure proper alignment of next section */
  } > aicore0_spm
#endif

  .aicore0.runtime.tls : ALIGN(64) {
    aicore0__tls_begin = .;
    . = . + aicore0__tls_alloc_size;
    aicore0__tls_end = .;
  } > aicore0_spm
  .aicore0.runtime.stack : ALIGN(64) {
    aicore0__stack_begin = .;
    . = . + AICORE_STACK_SIZE;
    aicore0__stack_end = .;
  } > aicore0_spm

  .aicore0.l1 : ALIGN(64) {
    *(.aicore0.l1)
  } > aicore0_l1

  .aicore0.ddr : ALIGN(64) {
    *(.aicore0.ddr)
  } > dram

  /* magic memory for UVM SW IPC communication */
  PROVIDE(aicore0__uvm_sw_ipc_mem = UVM_SW_IPC_BASE);
#endif

  /* ======= */
  /* AICORE1 */
  /* ======= */
#if PROCESSOR_AICORE1
  .aicore1.text : ALIGN(64) {
    KEEP(*(.aicore1.text.init))
    *(.aicore1.text .aicore1.text.*)
  } > aicore1_spm
  ASSERT(
    ADDR(.aicore1.text) == ORIGIN(aicore1_spm),
    "Error: AICORE1 boot code not at start of AICORE1 SPM"
  )
  .aicore1.data : ALIGN(64) {
    *(.aicore1.operation_data_type.*)
    *(.aicore1.rodata .aicore1.rodata.*)
    *(.aicore1.data .aicore1.data.*)
  } > aicore1_spm
  .aicore1.sdata : ALIGN(64) {
    aicore1___global_pointer$ = . + 0x800;
    *(.aicore1.srodata .aicore1.srodata.*)
    *(.aicore1.sdata .aicore1.sdata.*)
  } > aicore1_spm
  .aicore1.sbss : ALIGN(64) {
    aicore1__bss_begin = .;
    *(.aicore1.sbss .aicore1.sbss.*)
  } > aicore1_spm
  .aicore1.bss : ALIGN(64) {
    *(.aicore1.bss .aicore1.bss.*)
    aicore1__bss_end = .;
  } > aicore1_spm

  /* Enable explicit allocation to AI Core 1 internal SPM from any core */
  .aicore1.spm : ALIGN(64) {
    *(*.aicore1.spm *.aicore1.spm.*)
  } > aicore1_spm

#ifndef SYSTEM_TOP
  /* TLS for AICORE 1 (standalone) */
  .aicore1.tdata : ALIGN(64) {
    aicore1__tdata_begin = .;
    *(.aicore1.tdata .aicore1.tdata.*)
    . = ALIGN(64);
    aicore1__tdata_end = .;
    aicore1__tbss_begin = .;
    *(.aicore1.tbss .aicore1.tbss.*)
    . = ALIGN(64);
    aicore1__tbss_end = .;
  } > aicore1_spm
  aicore1__tls_alloc_size = aicore1__tbss_end - aicore1__tdata_begin;

  /* magic memory for FESVR communication */
  .tohost : ALIGN(0x1000) {
    *(.tohost)
    *(.*.tohost)
    . = ALIGN(0x1000); /* ensure proper alignment of next section */
  } > aicore1_spm
#endif

  .aicore1.runtime.tls : ALIGN(64) {
    aicore1__tls_begin = .;
    . = . + aicore1__tls_alloc_size;
    aicore1__tls_end = .;
  } > aicore1_spm
  .aicore1.runtime.stack : ALIGN(64) {
    aicore1__stack_begin = .;
    . = . + AICORE_STACK_SIZE;
    aicore1__stack_end = .;
  } > aicore1_spm

  .aicore1.l1 : ALIGN(64) {
    *(.aicore1.l1)
  } > aicore1_l1

  .aicore1.ddr : ALIGN(64) {
    *(.aicore1.ddr)
  } > dram

  /* magic memory for UVM SW IPC communication */
  PROVIDE(aicore1__uvm_sw_ipc_mem = UVM_SW_IPC_BASE);
#endif

  /* ======= */
  /* AICORE2 */
  /* ======= */
#if PROCESSOR_AICORE2
  .aicore2.text : ALIGN(64) {
    KEEP(*(.aicore2.text.init))
    *(.aicore2.text .aicore2.text.*)
  } > aicore2_spm
  ASSERT(
    ADDR(.aicore2.text) == ORIGIN(aicore2_spm),
    "Error: AICORE2 boot code not at start of AICORE2 SPM"
  )
  .aicore2.data : ALIGN(64) {
    *(.aicore2.operation_data_type.*)
    *(.aicore2.rodata .aicore2.rodata.*)
    *(.aicore2.data .aicore2.data.*)
  } > aicore2_spm
  .aicore2.sdata : ALIGN(64) {
    aicore2___global_pointer$ = . + 0x800;
    *(.aicore2.srodata .aicore2.srodata.*)
    *(.aicore2.sdata .aicore2.sdata.*)
  } > aicore2_spm
  .aicore2.sbss : ALIGN(64) {
    aicore2__bss_begin = .;
    *(.aicore2.sbss .aicore2.sbss.*)
  } > aicore2_spm
  .aicore2.bss : ALIGN(64) {
    *(.aicore2.bss .aicore2.bss.*)
    aicore2__bss_end = .;
  } > aicore2_spm

  /* Enable explicit allocation to AI Core 2 internal SPM from any core */
  .aicore2.spm : ALIGN(64) {
    *(*.aicore2.spm *.aicore2.spm.*)
  } > aicore2_spm

#ifndef SYSTEM_TOP
  /* TLS for AICORE 2 (standalone) */
  .aicore2.tdata : ALIGN(64) {
    aicore2__tdata_begin = .;
    *(.aicore2.tdata .aicore2.tdata.*)
    . = ALIGN(64);
    aicore2__tdata_end = .;
    aicore2__tbss_begin = .;
    *(.aicore2.tbss .aicore2.tbss.*)
    . = ALIGN(64);
    aicore2__tbss_end = .;
  } > aicore2_spm
  aicore2__tls_alloc_size = aicore2__tbss_end - aicore2__tdata_begin;

  /* magic memory for FESVR communication */
  .tohost : ALIGN(0x1000) {
    *(.tohost)
    *(.*.tohost)
    . = ALIGN(0x1000); /* ensure proper alignment of next section */
  } > aicore2_spm
#endif

  .aicore2.runtime.tls : ALIGN(64) {
    aicore2__tls_begin = .;
    . = . + aicore2__tls_alloc_size;
    aicore2__tls_end = .;
  } > aicore2_spm
  .aicore2.runtime.stack : ALIGN(64) {
    aicore2__stack_begin = .;
    . = . + AICORE_STACK_SIZE;
    aicore2__stack_end = .;
  } > aicore2_spm

  .aicore2.l1 : ALIGN(64) {
    *(.aicore2.l1)
  } > aicore2_l1

  .aicore2.ddr : ALIGN(64) {
    *(.aicore2.ddr)
  } > dram

  /* magic memory for UVM SW IPC communication */
  PROVIDE(aicore2__uvm_sw_ipc_mem = UVM_SW_IPC_BASE);
#endif

  /* ======= */
  /* AICORE3 */
  /* ======= */
#if PROCESSOR_AICORE3
  .aicore3.text : ALIGN(64) {
    KEEP(*(.aicore3.text.init))
    *(.aicore3.text .aicore3.text.*)
  } > aicore3_spm
  ASSERT(
    ADDR(.aicore3.text) == ORIGIN(aicore3_spm),
    "Error: AICORE3 boot code not at start of AICORE3 SPM"
  )
  .aicore3.data : ALIGN(64) {
    *(.aicore3.operation_data_type.*)
    *(.aicore3.rodata .aicore3.rodata.*)
    *(.aicore3.data .aicore3.data.*)
  } > aicore3_spm
  .aicore3.sdata : ALIGN(64) {
    aicore3___global_pointer$ = . + 0x800;
    *(.aicore3.srodata .aicore3.srodata.*)
    *(.aicore3.sdata .aicore3.sdata.*)
  } > aicore3_spm
  .aicore3.sbss : ALIGN(64) {
    aicore3__bss_begin = .;
    *(.aicore3.sbss .aicore3.sbss.*)
  } > aicore3_spm
  .aicore3.bss : ALIGN(64) {
    *(.aicore3.bss .aicore3.bss.*)
    aicore3__bss_end = .;
  } > aicore3_spm

  /* Enable explicit allocation to AI Core 3 internal SPM from any core */
  .aicore3.spm : ALIGN(64) {
    *(*.aicore3.spm *.aicore3.spm.*)
  } > aicore3_spm

#ifndef SYSTEM_TOP
  /* TLS for AICORE 3 (standalone) */
  .aicore3.tdata : ALIGN(64) {
    aicore3__tdata_begin = .;
    *(.aicore3.tdata .aicore3.tdata.*)
    . = ALIGN(64);
    aicore3__tdata_end = .;
    aicore3__tbss_begin = .;
    *(.aicore3.tbss .aicore3.tbss.*)
    . = ALIGN(64);
    aicore3__tbss_end = .;
  } > aicore3_spm
  aicore3__tls_alloc_size = aicore3__tbss_end - aicore3__tdata_begin;

  /* magic memory for FESVR communication */
  .tohost : ALIGN(0x1000) {
    *(.tohost)
    *(.*.tohost)
    . = ALIGN(0x1000); /* ensure proper alignment of next section */
  } > aicore3_spm
#endif

  .aicore3.runtime.tls : ALIGN(64) {
    aicore3__tls_begin = .;
    . = . + aicore3__tls_alloc_size;
    aicore3__tls_end = .;
  } > aicore3_spm
  .aicore3.runtime.stack : ALIGN(64) {
    aicore3__stack_begin = .;
    . = . + AICORE_STACK_SIZE;
    aicore3__stack_end = .;
  } > aicore3_spm

  .aicore3.l1 : ALIGN(64) {
    *(.aicore3.l1)
  } > aicore3_l1

  .aicore3.ddr : ALIGN(64) {
    *(.aicore3.ddr)
  } > dram

  /* magic memory for UVM SW IPC communication */
  PROVIDE(aicore3__uvm_sw_ipc_mem = UVM_SW_IPC_BASE);
#endif

  /* ======= */
  /* AICORE4 */
  /* ======= */
#if PROCESSOR_AICORE4
  .aicore4.text : ALIGN(64) {
    KEEP(*(.aicore4.text.init))
    *(.aicore4.text .aicore4.text.*)
  } > aicore4_spm
  ASSERT(
    ADDR(.aicore4.text) == ORIGIN(aicore4_spm),
    "Error: AICORE4 boot code not at start of AICORE4 SPM"
  )
  .aicore4.data : ALIGN(64) {
    *(.aicore4.operation_data_type.*)
    *(.aicore4.rodata .aicore4.rodata.*)
    *(.aicore4.data .aicore4.data.*)
  } > aicore4_spm
  .aicore4.sdata : ALIGN(64) {
    aicore4___global_pointer$ = . + 0x800;
    *(.aicore4.srodata .aicore4.srodata.*)
    *(.aicore4.sdata .aicore4.sdata.*)
  } > aicore4_spm
  .aicore4.sbss : ALIGN(64) {
    aicore4__bss_begin = .;
    *(.aicore4.sbss .aicore4.sbss.*)
  } > aicore4_spm
  .aicore4.bss : ALIGN(64) {
    *(.aicore4.bss .aicore4.bss.*)
    aicore4__bss_end = .;
  } > aicore4_spm

  /* Enable explicit allocation to AI Core 4 internal SPM from any core */
  .aicore4.spm : ALIGN(64) {
    *(*.aicore4.spm *.aicore4.spm.*)
  } > aicore4_spm

#ifndef SYSTEM_TOP
  /* TLS for AICORE 4 (standalone) */
  .aicore4.tdata : ALIGN(64) {
    aicore4__tdata_begin = .;
    *(.aicore4.tdata .aicore4.tdata.*)
    . = ALIGN(64);
    aicore4__tdata_end = .;
    aicore4__tbss_begin = .;
    *(.aicore4.tbss .aicore4.tbss.*)
    . = ALIGN(64);
    aicore4__tbss_end = .;
  } > aicore4_spm
  aicore4__tls_alloc_size = aicore4__tbss_end - aicore4__tdata_begin;

  /* magic memory for FESVR communication */
  .tohost : ALIGN(0x1000) {
    *(.tohost)
    *(.*.tohost)
    . = ALIGN(0x1000); /* ensure proper alignment of next section */
  } > aicore4_spm
#endif

  .aicore4.runtime.tls : ALIGN(64) {
    aicore4__tls_begin = .;
    . = . + aicore4__tls_alloc_size;
    aicore4__tls_end = .;
  } > aicore4_spm
  .aicore4.runtime.stack : ALIGN(64) {
    aicore4__stack_begin = .;
    . = . + AICORE_STACK_SIZE;
    aicore4__stack_end = .;
  } > aicore4_spm

  .aicore4.l1 : ALIGN(64) {
    *(.aicore4.l1)
  } > aicore4_l1

  .aicore4.ddr : ALIGN(64) {
    *(.aicore4.ddr)
  } > dram

  /* magic memory for UVM SW IPC communication */
  PROVIDE(aicore4__uvm_sw_ipc_mem = UVM_SW_IPC_BASE);
#endif

  /* ======= */
  /* AICORE5 */
  /* ======= */
#if PROCESSOR_AICORE5
  .aicore5.text : ALIGN(64) {
    KEEP(*(.aicore5.text.init))
    *(.aicore5.text .aicore5.text.*)
  } > aicore5_spm
  ASSERT(
    ADDR(.aicore5.text) == ORIGIN(aicore5_spm),
    "Error: AICORE5 boot code not at start of AICORE5 SPM"
  )
  .aicore5.data : ALIGN(64) {
    *(.aicore5.operation_data_type.*)
    *(.aicore5.rodata .aicore5.rodata.*)
    *(.aicore5.data .aicore5.data.*)
  } > aicore5_spm
  .aicore5.sdata : ALIGN(64) {
    aicore5___global_pointer$ = . + 0x800;
    *(.aicore5.srodata .aicore5.srodata.*)
    *(.aicore5.sdata .aicore5.sdata.*)
  } > aicore5_spm
  .aicore5.sbss : ALIGN(64) {
    aicore5__bss_begin = .;
    *(.aicore5.sbss .aicore5.sbss.*)
  } > aicore5_spm
  .aicore5.bss : ALIGN(64) {
    *(.aicore5.bss .aicore5.bss.*)
    aicore5__bss_end = .;
  } > aicore5_spm

  /* Enable explicit allocation to AI Core 5 internal SPM from any core */
  .aicore5.spm : ALIGN(64) {
    *(*.aicore5.spm *.aicore5.spm.*)
  } > aicore5_spm

#ifndef SYSTEM_TOP
  /* TLS for AICORE 5 (standalone) */
  .aicore5.tdata : ALIGN(64) {
    aicore5__tdata_begin = .;
    *(.aicore5.tdata .aicore5.tdata.*)
    . = ALIGN(64);
    aicore5__tdata_end = .;
    aicore5__tbss_begin = .;
    *(.aicore5.tbss .aicore5.tbss.*)
    . = ALIGN(64);
    aicore5__tbss_end = .;
  } > aicore5_spm
  aicore5__tls_alloc_size = aicore5__tbss_end - aicore5__tdata_begin;

  /* magic memory for FESVR communication */
  .tohost : ALIGN(0x1000) {
    *(.tohost)
    *(.*.tohost)
    . = ALIGN(0x1000); /* ensure proper alignment of next section */
  } > aicore5_spm
#endif

  .aicore5.runtime.tls : ALIGN(64) {
    aicore5__tls_begin = .;
    . = . + aicore5__tls_alloc_size;
    aicore5__tls_end = .;
  } > aicore5_spm
  .aicore5.runtime.stack : ALIGN(64) {
    aicore5__stack_begin = .;
    . = . + AICORE_STACK_SIZE;
    aicore5__stack_end = .;
  } > aicore5_spm

  .aicore5.l1 : ALIGN(64) {
    *(.aicore5.l1)
  } > aicore5_l1

  .aicore5.ddr : ALIGN(64) {
    *(.aicore5.ddr)
  } > dram

  /* magic memory for UVM SW IPC communication */
  PROVIDE(aicore5__uvm_sw_ipc_mem = UVM_SW_IPC_BASE);
#endif

  /* ======= */
  /* AICORE6 */
  /* ======= */
#if PROCESSOR_AICORE6
  .aicore6.text : ALIGN(64) {
    KEEP(*(.aicore6.text.init))
    *(.aicore6.text .aicore6.text.*)
  } > aicore6_spm
  ASSERT(
    ADDR(.aicore6.text) == ORIGIN(aicore6_spm),
    "Error: AICORE6 boot code not at start of AICORE6 SPM"
  )
  .aicore6.data : ALIGN(64) {
    *(.aicore6.operation_data_type.*)
    *(.aicore6.rodata .aicore6.rodata.*)
    *(.aicore6.data .aicore6.data.*)
  } > aicore6_spm
  .aicore6.sdata : ALIGN(64) {
    aicore6___global_pointer$ = . + 0x800;
    *(.aicore6.srodata .aicore6.srodata.*)
    *(.aicore6.sdata .aicore6.sdata.*)
  } > aicore6_spm
  .aicore6.sbss : ALIGN(64) {
    aicore6__bss_begin = .;
    *(.aicore6.sbss .aicore6.sbss.*)
  } > aicore6_spm
  .aicore6.bss : ALIGN(64) {
    *(.aicore6.bss .aicore6.bss.*)
    aicore6__bss_end = .;
  } > aicore6_spm

  /* Enable explicit allocation to AI Core 6 internal SPM from any core */
  .aicore6.spm : ALIGN(64) {
    *(*.aicore6.spm *.aicore6.spm.*)
  } > aicore6_spm

#ifndef SYSTEM_TOP
  /* TLS for AICORE 6 (standalone) */
  .aicore6.tdata : ALIGN(64) {
    aicore6__tdata_begin = .;
    *(.aicore6.tdata .aicore6.tdata.*)
    . = ALIGN(64);
    aicore6__tdata_end = .;
    aicore6__tbss_begin = .;
    *(.aicore6.tbss .aicore6.tbss.*)
    . = ALIGN(64);
    aicore6__tbss_end = .;
  } > aicore6_spm
  aicore6__tls_alloc_size = aicore6__tbss_end - aicore6__tdata_begin;

  /* magic memory for FESVR communication */
  .tohost : ALIGN(0x1000) {
    *(.tohost)
    *(.*.tohost)
    . = ALIGN(0x1000); /* ensure proper alignment of next section */
  } > aicore6_spm
#endif

  .aicore6.runtime.tls : ALIGN(64) {
    aicore6__tls_begin = .;
    . = . + aicore6__tls_alloc_size;
    aicore6__tls_end = .;
  } > aicore6_spm
  .aicore6.runtime.stack : ALIGN(64) {
    aicore6__stack_begin = .;
    . = . + AICORE_STACK_SIZE;
    aicore6__stack_end = .;
  } > aicore6_spm

  .aicore6.l1 : ALIGN(64) {
    *(.aicore6.l1)
  } > aicore6_l1

  .aicore6.ddr : ALIGN(64) {
    *(.aicore6.ddr)
  } > dram

  /* magic memory for UVM SW IPC communication */
  PROVIDE(aicore6__uvm_sw_ipc_mem = UVM_SW_IPC_BASE);
#endif

  /* ======= */
  /* AICORE7 */
  /* ======= */
#if PROCESSOR_AICORE7
  .aicore7.text : ALIGN(64) {
    KEEP(*(.aicore7.text.init))
    *(.aicore7.text .aicore7.text.*)
  } > aicore7_spm
  ASSERT(
    ADDR(.aicore7.text) == ORIGIN(aicore7_spm),
    "Error: AICORE7 boot code not at start of AICORE7 SPM"
  )
  .aicore7.data : ALIGN(64) {
    *(.aicore7.operation_data_type.*)
    *(.aicore7.rodata .aicore7.rodata.*)
    *(.aicore7.data .aicore7.data.*)
  } > aicore7_spm
  .aicore7.sdata : ALIGN(64) {
    aicore7___global_pointer$ = . + 0x800;
    *(.aicore7.srodata .aicore7.srodata.*)
    *(.aicore7.sdata .aicore7.sdata.*)
  } > aicore7_spm
  .aicore7.sbss : ALIGN(64) {
    aicore7__bss_begin = .;
    *(.aicore7.sbss .aicore7.sbss.*)
  } > aicore7_spm
  .aicore7.bss : ALIGN(64) {
    *(.aicore7.bss .aicore7.bss.*)
    aicore7__bss_end = .;
  } > aicore7_spm

  /* Enable explicit allocation to AI Core 7 internal SPM from any core */
  .aicore7.spm : ALIGN(64) {
    *(*.aicore7.spm *.aicore7.spm.*)
  } > aicore7_spm

#ifndef SYSTEM_TOP
  /* TLS for AICORE 7 (standalone) */
  .aicore7.tdata : ALIGN(64) {
    aicore7__tdata_begin = .;
    *(.aicore7.tdata .aicore7.tdata.*)
    . = ALIGN(64);
    aicore7__tdata_end = .;
    aicore7__tbss_begin = .;
    *(.aicore7.tbss .aicore7.tbss.*)
    . = ALIGN(64);
    aicore7__tbss_end = .;
  } > aicore7_spm
  aicore7__tls_alloc_size = aicore7__tbss_end - aicore7__tdata_begin;

  /* magic memory for FESVR communication */
  .tohost : ALIGN(0x1000) {
    *(.tohost)
    *(.*.tohost)
    . = ALIGN(0x1000); /* ensure proper alignment of next section */
  } > aicore7_spm
#endif

  .aicore7.runtime.tls : ALIGN(64) {
    aicore7__tls_begin = .;
    . = . + aicore7__tls_alloc_size;
    aicore7__tls_end = .;
  } > aicore7_spm
  .aicore7.runtime.stack : ALIGN(64) {
    aicore7__stack_begin = .;
    . = . + AICORE_STACK_SIZE;
    aicore7__stack_end = .;
  } > aicore7_spm

  .aicore7.l1 : ALIGN(64) {
    *(.aicore7.l1)
  } > aicore7_l1

  .aicore7.ddr : ALIGN(64) {
    *(.aicore7.ddr)
  } > dram

  /* magic memory for UVM SW IPC communication */
  PROVIDE(aicore7__uvm_sw_ipc_mem = UVM_SW_IPC_BASE);
#endif


  /* ==== */
  /* PVE0 */
  /* ==== */
#if PROCESSOR_PVE0
  .pve0.text.init : ALIGN(64) {
    KEEP(*(.pve0.text.init))
  } > pve0_spm
  ASSERT(
    ADDR(.pve0.text.init) == ORIGIN(pve0_spm),
    "Error: PVE0 boot code not at start of PVE0 SPM"
  )
  .pve0.text : ALIGN(64) {
    *(.pve0.text .pve0.text.*)
  } > pve0_spm
  .pve0.data : ALIGN(64) {
    *(.pve0.rodata .pve0.rodata.*)
    *(.pve0.data .pve0.data.*)
  } > pve0_spm
  .pve0.sdata : ALIGN(64) {
    pve0___global_pointer$ = . + 0x800;
    *(.pve0.srodata .pve0.srodata.*)
    *(.pve0.sdata .pve0.sdata.*)
  } > pve0_spm
  .pve0.sbss : ALIGN(64) {
    pve0__bss_begin = .;
    *(.pve0.sbss .pve0.sbss.*)
  } > pve0_spm
  .pve0.bss : ALIGN(64) {
    *(.pve0.bss .pve0.bss.*)
    pve0__bss_end = .;
  } > pve0_spm

#ifndef SYSTEM_TOP
  /* TLS for PVE 0 (standalone) */
  .pve0.tdata : ALIGN(64) {
    pve0__tdata_begin = .;
    *(.pve0.tdata .pve0.tdata.*)
    . = ALIGN(64);
    pve0__tdata_end = .;
    pve0__tbss_begin = .;
    *(.pve0.tbss .pve0.tbss.*)
    . = ALIGN(64);
    pve0__tbss_end = .;
  } > pve0_spm
  pve0__tls_alloc_size = pve0__tbss_end - pve0__tdata_begin;
#endif

  .pve0.runtime.tls : ALIGN(64) {
    pve0__tls_begin = .;
    . = . + 8 * pve0__tls_alloc_size;
    pve0__tls_end = .;
  } > pve0_spm
  .pve0.runtime.stack : ALIGN(64) {
    pve0__stack_begin = .;
    . = . + 8 * PVE_STACK_SIZE;
    pve0__stack_end = .;
  } > pve0_spm

  .pve0.l1 : ALIGN(64) {
    *(.pve0.l1)
  } > pve0_l1_0

  .pve0.ddr : ALIGN(64) {
    *(.pve0.ddr)
  } > dram

  /* magic memory for UVM SW IPC communication */
  PROVIDE(pve0__uvm_sw_ipc_mem = UVM_SW_IPC_BASE);
#endif
  /* ==== */
  /* PVE1 */
  /* ==== */
#if PROCESSOR_PVE1
  .pve1.text.init : ALIGN(64) {
    KEEP(*(.pve1.text.init))
  } > pve1_spm
  ASSERT(
    ADDR(.pve1.text.init) == ORIGIN(pve1_spm),
    "Error: PVE1 boot code not at start of PVE1 SPM"
  )
  .pve1.text : ALIGN(64) {
    *(.pve1.text .pve1.text.*)
  } > pve1_spm
  .pve1.data : ALIGN(64) {
    *(.pve1.rodata .pve1.rodata.*)
    *(.pve1.data .pve1.data.*)
  } > pve1_spm
  .pve1.sdata : ALIGN(64) {
    pve1___global_pointer$ = . + 0x800;
    *(.pve1.srodata .pve1.srodata.*)
    *(.pve1.sdata .pve1.sdata.*)
  } > pve1_spm
  .pve1.sbss : ALIGN(64) {
    pve1__bss_begin = .;
    *(.pve1.sbss .pve1.sbss.*)
  } > pve1_spm
  .pve1.bss : ALIGN(64) {
    *(.pve1.bss .pve1.bss.*)
    pve1__bss_end = .;
  } > pve1_spm

#ifndef SYSTEM_TOP
  /* TLS for PVE 1 (standalone) */
  .pve1.tdata : ALIGN(64) {
    pve1__tdata_begin = .;
    *(.pve1.tdata .pve1.tdata.*)
    . = ALIGN(64);
    pve1__tdata_end = .;
    pve1__tbss_begin = .;
    *(.pve1.tbss .pve1.tbss.*)
    . = ALIGN(64);
    pve1__tbss_end = .;
  } > pve1_spm
  pve1__tls_alloc_size = pve1__tbss_end - pve1__tdata_begin;
#endif

  .pve1.runtime.tls : ALIGN(64) {
    pve1__tls_begin = .;
    . = . + 8 * pve1__tls_alloc_size;
    pve1__tls_end = .;
  } > pve1_spm
  .pve1.runtime.stack : ALIGN(64) {
    pve1__stack_begin = .;
    . = . + 8 * PVE_STACK_SIZE;
    pve1__stack_end = .;
  } > pve1_spm

  .pve1.l1 : ALIGN(64) {
    *(.pve1.l1)
  } > pve1_l1_0

  .pve1.ddr : ALIGN(64) {
    *(.pve1.ddr)
  } > dram

  /* magic memory for UVM SW IPC communication */
  PROVIDE(pve1__uvm_sw_ipc_mem = UVM_SW_IPC_BASE);
#endif


  /* discard everything else */
  /DISCARD/ : {
    *(.text .text.*)
    *(.rodata .rodata.*)
    *(.data .data.*)
    *(.bss .bss.*)
    *(.sdata .sdata.*)
    *(.sbss .sbss.*)
    *(.scommon .scommon.*)
    *(.tdata .tdata.*)
    *(.tbss .tbss.*)
    *(.ddr .ddr.*)
    *(.l2 .l2.*)
    *(.aicore0.*)
    *(.pve0.*)
    *(.tohost)
  }
}
